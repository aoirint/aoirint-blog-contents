---
title: テキスト読み上げソフトVOICEVOXのビルドを自動化した（モチベーション編）
draft: true
date: '2021-12-15T7:00+09:00'
channel: 技術ノート
category: レポート
tags:
    - 'CI CD'
    - 'GitHub Actions'
    - 音声合成
---
# テキスト読み上げソフトVOICEVOXのビルドを自動化した（モチベーション編）

- [目次](../voicevox_autobuild/)

---

- 内容
  - コンテキストの共有
  - モチベーションの確認
  - 技術情報の共有

---

## ここを必ず読んでね

こちらの記事は、1コントリビュータ、1ユーザのふわっとした感想文で、勝手に書いた体験記になります。

**VOICEVOXの今後の活躍と、開発の一助になればと思い、記事として作ってみました。**

コンテキスト共有のために、ググりながら背景など記述してみますが、**正確でない表現が含まれている可能性があります**ので、ご注意くださいませ。

## モチベーション

自分のモチベーションを把握しておきたいので、個人的なことになりますが、経緯を書いてみます。

- 実質的な音声知識はほぼない
    - OpenJTalkのTTS機能を使っていた
    - 2019年5月頃に音声認識どうやったらできるのかスケッチを描いていた
        - 既存手法もまったく知らないので、むずかしそうだなぁということがわかった
    - 2019年6月頃にMLP 音声認識を積んでいた
        - 既存手法を知りたかった
    - 2021年5月頃に音声分析合成を積んでいた
        - CoeFont（4月）と七声ニーナ（5月）が背景
    - 2021年6月頃にA.I.VOICE 琴葉葵・茜を購入
- 深層学習
    - 流行ったときに画像系でChainer・PyTorchでちょっとした論文実装を書いたり書かなかったり
- 開発
    - Java、ちょっとだけPHP経験を背景
    - Web、ちょっとだけモバイル
    - Python、ちょっとだけTypeScriptが書ける
    - Dockerイメージをよく作っている

音声合成界隈には、VOICEROID・ソフトウェアトーク動画などを通じて興味を持っていました。

8月1日の朝9時ごろ、東北ずん子公式さんのツイートがTLに流れてきました。

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">こちらが、めたんちゃん、ずんだもんの音声合成ソフトVOICEVOXになりますo(≧▽≦)o<a href="https://t.co/khcYXoN0pR">https://t.co/khcYXoN0pR</a> <a href="https://t.co/tb09I4K5dI">pic.twitter.com/tb09I4K5dI</a></p>&mdash; 東北ずん子(公式)💚12月23日26時25分から東北放送でTV放送 (@t_zunko) <a href="https://twitter.com/t_zunko/status/1421485817319546884?ref_src=twsrc%5Etfw">July 31, 2021</a></blockquote>

無料で使えるいい感じの品質の音声合成ソフトがあるらしいぞ、ということで、これをきっかけにして、ふだん自分が使っている環境のLinux（Ubuntu）上での動作を試み始めました。

この時点ではWindowsバイナリのみの提供でしたが、もともと個人的に、他のWindowsバイナリしかない研究用ライブラリをLinux上で動かすために、
[Wine in Docker環境を作成していた](https://twitter.com/aoirint/status/1381667075341447169)ので、
それを改変してVOICEVOXソフトウェアを動かしてみました。

<blockquote class="twitter-tweet"><p lang="und" dir="ltr"><a href="https://t.co/WuOGw8LUTj">pic.twitter.com/WuOGw8LUTj</a></p>&mdash; aoi🌱 (@aoirint) <a href="https://twitter.com/aoirint/status/1424142369046155268?ref_src=twsrc%5Etfw">August 7, 2021</a></blockquote>

初期のバージョン（上の動画は0.1.1）では、ちょっと音声がかすれ気味だったり、CPU版での合成に長めの時間がかかったりしていました。
これについては、バージョンが上がることで音声品質や合成速度にも調整が加えられています。

0.5まで、製品版音声ライブラリは、製品版ソフトウェアに同梱されたWindows向け（DLL）のみ存在していたため、Wineや仮想環境を介さずネイティブ動作させることはできませんでした。

[0.5.2](https://github.com/VOICEVOX/voicevox_core/releases/tag/0.5.2)で、Linux向けライブラリ（SO）を含む音声ライブラリ単体の提供が始まったので、
その後のバージョンでソフトウェアのLinuxネイティブ対応や自動ビルドができるようになりました。

### 過去のOSS貢献の経験

OSSにプルリクエストを送った経験がほとんどなかったので、まずは小さいパッチを送って様子を見たいと思いました。

- [https://github.com/miyadaiku/miyadaiku/pull/43](https://github.com/miyadaiku/miyadaiku/pull/43)
- [https://github.com/miyadaiku/miyadaiku/pull/44](https://github.com/miyadaiku/miyadaiku/pull/44)

身内以外へのプルリクエストは、上のMiyadaikuというPython製静的サイトジェネレータが初めてでした。

前々から追加したい機能があって、fork・改造して使っていたのですが、
本家にアップデートがあるたびにマージコミットを作ったりrebaseしたり、
gitリポジトリからパッケージをインストールしたりが面倒だったので、
取り込んでもらえないか試してみることにしました。

似た機能の要望Issueが自分の望む方法とは別の方法で実装されていて、
それでは目的を達成できませんでした。

いきなり機能追加提案やパッチを送っても、受け入れられるかよくわかりませんでした。

そもそも機能提案やプルリクエストを受け付けているのか、
開発上どういうルールがあるのか（開発の進め方とか、方針とか、コードフォーマットとか）、
メンテナの人となり、

メンテナにとっても、誰かよくわからない人が送ってきたパッチよりも、
過去にいい貢献をしてくれた人が送ってきたパッチのほうがポジティブに見ることができるかなと勝手に思っています。
機能提案があったとき、それがプロジェクトの方針に合っているか判断する必要があります。

相手が勘違いしていて的外れなことを言っている場合もあれば、
意図をうまく伝えられず、勘違いされてしまう場合もあると思っています。

実装や方針、プロジェクトで大切にしていることを読み取っておかなければ、ただ迷惑をかけたり、手間をかけさせたりしただけになってしまいます。

小さなパッチがRejectされても、


自分が使う上でバグを見つけていたので、まず小さいバグ修正パッチを送り、それから機能追加提案にあたるパッチを送りました。
変更内容が小さかったので、機能提案ついでにパッチを作りましたが、Issueを立てて実装方針を確認・議論することがだいたい望ましいと思います。

一度軽くコミュニケーションをとって、お互いの雰囲気や実装方針を読み取るために、まず小さなパッチを送ってみました。
